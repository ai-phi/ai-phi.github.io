---
author: AI-PHI
pubDatetime: 2025-06-26T11:00:00Z
# modDatetime:
title: >-
  Session 25- Kathinka Evers (Uppsala University) - Artificial Consciousness: Science Fiction, Utopia, or Pandora’s Box?
slug: session-25-kathinka-evers
draft: false
featured: false
nextSession: false
nextFormal: true
tags:
  - Seminar Series
  - Artificial Consciousness
  - Neuroethics
description: Katharina explores why the question of artificial sentience (or “awareness”, or “consciousness”) is raised in science receiving considerable public funding despite the lack of empirical evidence? What this might mean and what the implications of it are.
session: true
ogImage: assets/ai-phi-session-25.png
---

## Artificial Consciousness: Science Fiction, Utopia, or Pandora’s Box?

The question whether a machine – a computer or a robot or any other form of artificial system – could be sentient is certainly entertaining, no end of science fiction deals with the question and sometimes very engagingly. But why is the question of artificial sentience (or “awareness”, or “consciousness”) raised in science receiving considerable public funding despite the lack of empirical evidence?

I shall address this question from distinct perspectives: scientific, psychological and social. I suggest that the human urge to develop conscious artificial systems is partly driven by hype but also by narcissism and naivety; unrealistic hopes for benefits are coupled with ignorance of possible risks. A dangerous combination, as history amply illustrates.

There is a tendency to underestimate the potential relevance of the change of substrate: from carbon to silicon, from living to non-living matter, when ascribing consciousness to artificial systems, and to consider subjective experience to be independent from the biological, living body. For example, in the functionalist perspective assuming that a system is conscious if it performs the right functions, whatever kind of matter it is made of. There are numerous problems with this theoretical approach, scientific as well as social and ethical.

The epistemic and psychological challenges introduced by the gaming problem are central. When artificial systems use human-generated training data to mimic human behaviours, they may, if successful, psychologically persuade human users of their sentience, as a form of anthropomorphism; yet logically, mimicking human behaviours in artificial systems has no evidential value whatsoever. This poses a formidable obstacle to detecting phenomenal consciousness in artificial systems trained with human-generated data and deeply influences our risk-benefit assessments in this domain. To avoid the gaming problem, we should arguably focus less exclusively on similarities and pay more attention to differences, for AI is not only materially but also functionally very different from a human brain. But here a different problem arises: the question of commensurability and how to justify the application of the same concept to such distinct phenomena.

Several interesting approaches have been articulated to identify benchmarks for artificial forms of phenomenal consciousness. However, in view of the mentioned logical and psychological challenges involved, the study of sentience in artificial systems might well in the end tell us more about humans than about the systems studied.

In view of how human nature has expressed itself throughout history, conscious AI created by humans would likely be monumentally dangerous. It could also be very different from human consciousness and thus (a) undetectable, (b) incomprehensible, and (c) incommunicable. This could increase the risks and cut both ways if the conscious AI has valenced experience.

## About Kathinka Evers

<img src="/assets/ai-phi-kathinka-evers-small.png" alt="A portrait of Kathinka Evers" />

Kathinka Evers is Professor of philosophy, senior researcher at the Centre for Research Ethics & Bioethics (CRB) at Uppsala University, Sweden, and Professor ad honoram at the Universidad Central de Chile, Santiago. She has been Invited Professor on the Chair Condorcet at École Normale Supérieure, Paris (2002); at Collège de France, Paris (2006 -7). 2013-21, she was member of the Science and Infrastructure Board of the European Flagship, the Human Brain Project (HBP), where she directed the Ethics and Society Subproject, and led the Philosophy and Neuroethics research. Today, Kathinka Evers co-leads philosophy research in the Horizon 2020-projects Neurotwin and CAVAA. Her research focuses on philosophy of mind and brain, bioethics and neuroethics. She directs the teaching and research on neuroethics at Uppsala University, where she started the first courses in the subject. She is also interested in the social responsibility of science and was between 1997 and 2002 Executive Director for the Standing Committee for Ethics and Responsibility in Science of the International Council for Science (ICSU); and 2008-2014 Expert in Scientific Review Panels for the ERC on ‘The Human Mind and Its Complexity’. Since her first public lectures at the University of Oxford in 1990, she has lectured extensively at universities and research centres in Europe, the U.S., South America, Asia, and Australia.

## Details

**Date and Time:** Wednesday, 26th of June 2025 - <u>**11 AM**</u>  
**Location:** Sony CSL, 6 rue Amyot, 75005 Paris  
**Registration:** [here](https://lu.ma/v0eezp2a)
