---
author: ai-phi
pubDatetime: 2026-02-12T18:00:00.000Z
title: Are We Losing Control?
slug: session-32-segerie-losing-control
sessionNumber: 28
titleShort: Are We Losing Control?
speakers:
  - name: Charbel-Raphaël Segerie
    affiliation: CeSIA
baseIllustration: /images/base/sessions/session-32-segerie-losing-control.png
draft: false
featured: true
tags:
  - Safety
  - Control
  - Alignment
  - Agentic Systems
  - Biotechnology
  - Deception
  - Risk Evaluation
  - Mechanistic Interpretability
  - RLHF
description: >-
  From the democratization of dual-use biotechnology to the emergence of deceptive agentic systems, the trajectory of Artificial Intelligence raises urgent questions about control and alignment. In this talk, Charbel-Raphaël Segerie presents a critical analysis of the current race toward superintelligence and the widening gap between technological capabilities and control mechanisms.
kind: seminar
series: AI-Phi Seminar Series
---

From the democratization of dual-use biotechnology to the emergence of deceptive agentic systems, the trajectory of Artificial Intelligence raises urgent questions about control and alignment. In this talk, Charbel-Raphaël Segerie presents a critical analysis of the current race toward superintelligence and the widening gap between technological capabilities and control mechanisms.

CeSIA (Centre pour la Sécurité de l'IA), which he co-founded and directs, sits at the intersection of technical AI safety research and international governance—serving as an official evaluator for the EU AI Act while leading the Global Call for AI Red Lines, an initiative endorsed by 12 Nobel laureates and presented at the UN Security Council. Segerie will discuss the technical challenges of aligning powerful models with human values and the policy frameworks necessary to address these risks.

## About Charbel-Raphaël Segerie

<img
  src="/images/base/sessions/session-32-segerie-losing-control.png"
  alt="Speaker portrait"
  class="speaker-portrait"
/>

Charbel-Raphael Segerie is the executive director of CeSIA, the French Center for AI Safety, and he is an OECD AI expert. He initiated and co-lead the Global Call for AI Red Lines, which was presented in the UN General Assembly. He was previously Head of AI at EffiSciences, and founded ML4Good, an AI safety bootcamp designed for researchers, which has now been reproduced 15 times worldwide. He created the curriculum for an AI safety course at ENS, which was the first university-accredited course in the EU on general-purpose AI safety. He has experience in the industry as a startup CTO and has worked in different French research institutions (Inria, Neurospin). He was the capstone teacher at Arena and taught AI Safety in Berkeley for the MLAB. His research focuses on identifying emerging risks in AI, and he has published influential pieces on the limitations of current safety methods, such as RLHF and mechanistic interpretability and AI risk evaluations. He contributed to the EU AI Office’s Code of Practice for general-purpose AI systems.

[Website](https://crsegerie.github.io/bio) / [LinkedIn](https://www.linkedin.com/in/charbel-raphael-segerie/) / [Twitter](https://twitter.com/CRSegerie) / [Github](https://github.com/crsegerie)

## Details

**Date and Time:** Thursday, 12th of February 2026 - **7 PM**  
**Location:** Sony CSL, 6 rue Amyot, 75005 Paris  
**Registration:** [here](https://luma.com/9v9fh6lp)
